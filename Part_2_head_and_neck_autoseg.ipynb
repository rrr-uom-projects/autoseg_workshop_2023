{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find out what GPU we got (and make sure we actually have one!)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download all the data! This may take a little while...\n",
    "\n",
    "## Processed data\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    !wget https://www.dropbox.com/s/la05h49y9ths7x3/autoseg_data.tar.gz?dl=0 -O /content/AllProcessedData.tar\n",
    "    !tar -xf /content/AllProcessedData.tar -C /content/\n",
    "    !rm /content/AllProcessedData.tar\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    !wget https://www.dropbox.com/s/la05h49y9ths7x3/autoseg_data.tar.gz?dl=0 -O ./AllProcessedData.tar\n",
    "    !tar -xf ./AllProcessedData.tar -C ./\n",
    "    !rm AllProcessedData.tar\n",
    "\n",
    "# utilities python file\n",
    "if IN_COLAB:\n",
    "    !wget https://www.dropbox.com/s/rng7h9mgkwaolt8/utils.py?dl=0 -O /content/utils.py\n",
    "else:\n",
    "    !wget https://www.dropbox.com/s/rng7h9mgkwaolt8/utils.py?dl=0 -O ./utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install prerequisites\n",
    "\n",
    "Here we install the pytorch flavour of the segmentation-models library, along with pydicom and pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
    "    %pip install pytorch_lightning tqdm ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up monitoring and enable matplotlib notebook interactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt \n",
    "import pytorch_lightning as pl\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "# import pydicom\n",
    "import torch\n",
    "import os\n",
    "from utils import getFiles\n",
    "from os.path import join\n",
    "import pickle\n",
    "## These are the structures defined in the FLARE data\n",
    "structure_names = ['Body', 'Brainstem', 'Mandible', 'Parotids', 'Spinalcord']\n",
    "## See if we're in colab...\n",
    "if IN_COLAB:\n",
    "    datapath = \"/content/HnN_data/\"\n",
    "else:\n",
    "    datapath = \"/home/ed/autoseg_workshop_2023/HnN_data/\"  ## <---- You will need to change this if running locally"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the HN data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the training data\n",
    "train_datapath = join(datapath, \"train\")\n",
    "fnames = sorted(getFiles(join(train_datapath, 'ims')))\n",
    "train_ct_slices = np.zeros((len(fnames), 192, 192), dtype=np.float32)\n",
    "train_mask_slices = np.zeros((len(fnames), 192, 192), dtype=np.float32)\n",
    "\n",
    "# Add your code here to load the data\n",
    "\n",
    "# load the data\n",
    "for fdx, fname in enumerate(fnames):\n",
    "    pass\n",
    "# load pixel spacing\n",
    "with open(join(train_datapath, \"spacings.pkl\"), \"rb\") as f:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Get the test data\n",
    "test_datapath = join(datapath, \"test\")\n",
    "fnames = sorted(getFiles(join(test_datapath, 'ims')))\n",
    "test_ct_slices = np.zeros((len(fnames), 192, 192), dtype=np.float32)\n",
    "test_mask_slices = np.zeros((len(fnames), 192, 192), dtype=np.float32)\n",
    "\n",
    "# Add your code here to load the data\n",
    "\n",
    "for fdx, fname in enumerate(fnames):\n",
    "    pass\n",
    "# load pixel spacing\n",
    "with open(join(test_datapath, \"spacings.pkl\"), \"rb\") as f:\n",
    "    pass\n",
    "\n",
    "print(train_ct_slices.shape)\n",
    "print(train_mask_slices.shape)\n",
    "print(test_ct_slices.shape)\n",
    "print(test_mask_slices.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a slightly smaller dataset of HnN data. Therefore we don't need to sample the data as heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "subset_indices = np.random.permutation(window_levelled_slices_train.shape[0])\n",
    "\n",
    "wl_slice_subset_train = window_levelled_slices_train[subset_indices[:400]]\n",
    "mask_subset_train = train_mask_slices[subset_indices[:400]]\n",
    "spacings_subset_train = np.array(list(train_pixel_sizes.values()))[subset_indices[:400]]\n",
    "\n",
    "wl_slice_subset_val = window_levelled_slices_train[subset_indices[400:]]\n",
    "mask_subset_val =  train_mask_slices[subset_indices[400:]]\n",
    "spacings_subset_val = np.array(list(train_pixel_sizes.values()))[subset_indices[400:]]\n",
    "\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dataset code and dataloaders here ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating the Segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add model code here ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add training code here ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run the evaluation over the entire test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add testing code here ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "### Your code here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
